name: CD

on:
  push:
    branches: ["main"]
  # workflow_run:
  #   workflows: ["CI"]
  #   types: ["completed"]

jobs:
  deploy-to-cluster:
    runs-on: self-hosted

    # ðŸ‘‡ Force ALL run steps to use Windows PowerShell (not pwsh)
    defaults:
      run:
        shell: powershell

    env:
      REGISTRY: ghcr.io
      IMAGE_NAME: walid-isga/timi-devops-poc
      K8S_NAMESPACE: timi
      K8S_DEPLOYMENT: timi-api
      KCTX: kind-timi

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Print shell to confirm
        run: |
          Write-Host "Using shell:" $PSVersionTable.PSVersion

      - name: Kubectl context + nodes
        run: |
          kubectl config use-context $env:KCTX
          kubectl get nodes

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pick image tag (prefer SHA, fallback to latest)
        id: picktag
        run: |
          $imgSha    = "$($env:REGISTRY)/$($env:IMAGE_NAME):$($env:GITHUB_SHA)"
          $imgLatest = "$($env:REGISTRY)/$($env:IMAGE_NAME):latest"

          function Test-Tag([string]$ref) {
            # Run under CMD to avoid PowerShell NativeCommandError surfacing
            cmd /c "docker manifest inspect $ref >NUL 2>&1"
            return ($LASTEXITCODE -eq 0)
          }

          if (Test-Tag $imgSha) {
            "use_tag=$($env:GITHUB_SHA)" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
            Write-Host "Using SHA tag: $imgSha"
          }
          elseif (Test-Tag $imgLatest) {
            "use_tag=latest" | Out-File -FilePath $env:GITHUB_OUTPUT -Append
            Write-Host "Using fallback :latest â†’ $imgLatest"
          }
          else {
            Write-Error "Neither $imgSha nor $imgLatest exists in GHCR."
            exit 1
          }


      - name: Apply manifests (ns/deploy/svc)
        run: |
          kubectl apply -f k8s/namespace.yaml
          kubectl apply -f k8s/deployment.yaml
          kubectl apply -f k8s/service.yaml

      - name: Set deployment image to chosen tag
        run: |
          if (-not "${{ steps.picktag.outputs.use_tag }}") { Write-Error "use_tag empty"; exit 1 }
          $tag = "${{ steps.picktag.outputs.use_tag }}"
          kubectl -n $env:K8S_NAMESPACE set image deployment/$env:K8S_DEPLOYMENT `
            $env:K8S_DEPLOYMENT="$($env:REGISTRY)/$($env:IMAGE_NAME):$tag"

      - name: Wait for rollout
        run: |
          kubectl -n $env:K8S_NAMESPACE rollout status deploy/$env:K8S_DEPLOYMENT --timeout=240s
          kubectl -n $env:K8S_NAMESPACE get pods -o wide
        
      - name: Smoke test /health and /chantiers
        shell: powershell
        run: |
          $ns  = "$($env:K8S_NAMESPACE)"
          $svc = "timi-api-svc.$ns.svc.cluster.local:5000"

          # Nettoyage si un pod test existe encore (idempotent)
          kubectl -n $ns delete pod curl-smoke-1,curl-smoke-2 --ignore-not-found | Out-Null

          # 1) /health doit renvoyer 200 (curl -f Ã©choue si code â‰  200)
          kubectl -n $ns run curl-smoke-1 --restart=Never --image=curlimages/curl:8.10.1 `
            -- curl -fsS http://$svc/health

          # 2) /chantiers doit renvoyer un tableau JSON (on vÃ©rifie qu'il y a un '[')
          kubectl -n $ns run curl-smoke-2 --restart=Never --image=curlimages/curl:8.10.1 `
            -- sh -lc "curl -fsS http://$svc/chantiers | grep '\['"

          # Nettoyage best-effort
          kubectl -n $ns delete pod curl-smoke-1,curl-smoke-2 --ignore-not-found | Out-Null


      - name: Annotate deployment with commit metadata
        if: success()
        run: |
          kubectl -n $env:K8S_NAMESPACE annotate deploy/$env:K8S_DEPLOYMENT `
            "app.commit-sha=$env:GITHUB_SHA" "app.run-id=$env:GITHUB_RUN_ID" --overwrite

      - name: Sanity check /health from inside cluster (ephemeral curl pod)
        run: |
          $ns  = "$($env:K8S_NAMESPACE)"
          $svc = "timi-api-svc.$ns.svc.cluster.local:5000"
          kubectl -n $ns delete pod curlcheck --ignore-not-found | Out-Null
          kubectl -n $ns run curlcheck --restart=Never --image=curlimages/curl:8.10.1 `
            -- curl -fsS http://$svc/health
          kubectl -n $ns delete pod curlcheck --ignore-not-found | Out-Null

      - name: Rollback on failure
        if: failure()
        run: |
          kubectl -n $env:K8S_NAMESPACE rollout undo deploy/$env:K8S_DEPLOYMENT
